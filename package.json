{
  "name": "thinkdrop-backend",
  "version": "1.0.0",
  "description": "Lightweight LLM streaming backend + OmniParser service for Thinkdrop",
  "main": "dist/index.js",
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js",
    "dev": "ts-node-dev --respawn --transpile-only src/index.ts",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.36.3",
    "@google/generative-ai": "^0.21.0",
    "@mistralai/mistralai": "^1.3.4",
    "axios": "^1.7.9",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^4.21.2",
    "ioredis": "^5.4.1",
    "openai": "^4.77.3",
    "replicate": "^1.0.1",
    "uuid": "^11.0.5",
    "winston": "^3.17.0",
    "ws": "^8.18.0"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/express": "^5.0.0",
    "@types/node": "^22.10.7",
    "@types/uuid": "^10.0.0",
    "@types/ws": "^8.5.13",
    "ts-node-dev": "^2.0.0",
    "typescript": "^5.7.3"
  }
}
